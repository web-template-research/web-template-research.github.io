<!DOCTYPE HTML>
<html>
    <head>
        <!--## Enter your webpage's title here -->
        <title>Your webpage title here</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=1000">
        <link rel="stylesheet" href="https://use.typekit.net/quv7bsd.css"> <!-- fonts -->
        <link rel="stylesheet" href="style.css" />
    </head>
    <body id="body">
        <div id="main"> 
            <header id="header">
            </header>
            <div id="profile">
                <div id="profile-desc">
                    <div id="profile-name" style="text-align: center; white-space: nowrap; font-size: 200%;">
                        <!--## Enter your paper's title here, br can used to change the line, you can also modify the 'style' command to change the font types or size -->
                        <b style="line-height: 1.5;">This is a webpage template for research projects: <br> Enter your paper's title here </b>
                        <p><br>Under Review</p>
                        <br>
                        <p>
                            <!--## Enter other information of your paper here, such as codes, paper link, etc. -->
                            <a href="https://github.com/">Code Coming Soon (GitHub)</a> &nbsp;&nbsp;
                            <a href="https://arxiv.org/">Paper (arXiv)</a>
                        </p>
                    </div>
                     <!--## Enter a cover figure of the paper -->
                    <div class="image" style="text-align: center; margin: 1em 0;">
                        <img src="images/Fig_3_cover_Figure_3.jpg" alt="Cover Figure" style="max-width: 100%; height: auto;" />
                    </div>
                    
                    <!--## Enter the abstract of the paper -->
                    <p>
                        <b>Abstract</b>. Behavior cloning (BC) traditionally relies on demonstration data, assuming the demonstrated actions are optimal. This can lead to overfitting under noisy data, particularly when expressive models are used (e.g., the energy-based model in Implicit BC). To address this, we extend behavior cloning into an iterative process of optimal action estimation within the Interactive Imitation Learning framework. Specifically, we introduce Contrastive policy Learning from Interactive Corrections (CLIC). CLIC leverages human corrections to estimate a set of desired actions and optimizes the policy to select actions from this set. We provide theoretical guarantees for the convergence of the desired action set to optimal actions in both single and multiple optimal action cases. Extensive simulation and real-robot experiments validate CLIC's advantages over existing state-of-the-art methods, including stable training of energy-based models, robustness to feedback noise, and adaptability to diverse feedback types beyond demonstrations.
                    </p>
                </div>
                <div style="clear: both;"></div>
            </div>
            
            <!-- Highlight part -->
            <div class="section paper">
                <!-- Define the headline using the template h1 -->
                <h1 style="margin-bottom: 0px">Highlights</h1>

                <!-- Display one video and one figures in one row -->
                <div class="section recent-work">
                    <!-- Define one video, change the source to your own video with a correct path.
                        You can adjust the height and width of this video.-->
                    <div class="highlight-proj">
                        <video height="240" width="100%" playsinline="" muted="" autoplay="" loop="">
                            <source src="images/video_CLIC_iteratively_converge.mp4" type="video/mp4">
                        </video>
                        <!-- Here defines the footnotes/captions of the above video.-->
                        <p style="font-size: 16px; margin-top: 0px; margin-left: 0px">Change the video and its corresponding caption.</p>
                    </div>
                    <!-- Here defines a figure, its size follows the class 'highlight-proj2in3' in style.css file.-->
                    <div class="highlight-proj2in3">
                        <!-- Adjust the sources and captions accordingly. 
                            Feel free to change the size of the figure.
                            If you don't need a figure here, just simply remove this section, starting from <div class="section recent-work"> to its corresponding </div>.-->
                        <div class="image" style="text-align: center; margin-top: 1em 0;">
                            <img src="images/CLIC_reduces_to_IBC2.png" alt="" style="height: 240px; width: auto;margin-left: -10px; margin-bottom:0 " />
                        </div>
                        <p style="font-size: 16px; margin-top: 0px; margin-left: 0px">Change the figure and its corresponding caption.</p>
                    </div>
                </div>
                
                <!-- Display three videos in one row-->
                <div class="section recent-work">
                    <div class="highlight-proj">
                        <video height="240" width="100%" playsinline="" muted="" autoplay="" loop="">
                            <source src="images/ball_catching_highligh.mp4" type="video/mp4">
                        </video>
                        <p style="font-size: 16px; margin-left: 0px">Ball catching: Quick coordination with <br>partial feedback to the end effector <br>or the robot hand.</p>
                    </div>
                    <div class="highlight-proj">
                        <video height="240" width="100%" playsinline="" muted="" autoplay="" loop="">
                            <source src="images/water-pouring_hightlight.mp4" type="video/mp4">
                        </video>
                        <p style="font-size: 16px; margin-left: 0px">Water pouring: Learning full pose <br>control to precisely pour <br>liquid (marbles) into a bowl.</p>
                    </div>
                    <div class="highlight-proj">
                        <video height="240" width="100%" playsinline="" muted="" autoplay="" loop="">
                            <source src="images/InsertT-highlight.mp4" type="video/mp4">
                        </video>
                        <p style="font-size: 16px; margin-left: 0px">Insert-T: Learning long-horizon multi-<br> modal task that inserts the T-shape <br>object into the U-shape object.</p>
                    </div>
                </div>

                <!--## You can add more video highlights below, just remove this if you don't need it. -->
                <div class="section recent-work">
                    <!--## Highlight individual task videos and clearly label each task -->
                    <p>You can add more video highlights, and you can also adjust the layout of these videos.</p><br>
                </div>
            </div>
            

            <div class="divider"></div>
            <br>


            <!-- simulation results -->
            <div class="section paper">
                <h1>Simulation benchmarks</h1>
                <p>Our CLIC method outperforms prior state-of-the-art on 4 tasks, where we consider various feedback types for each task. Examples of the trajectory rollout of CLIC method (after training) using accurate demonstration are shown in the video below:</p><br>

                
                <video height="auto" width="100%" playsinline="" muted="" autoplay="" loop="">
                    <source src="images/CLIC_simulation_compressed.mp4" type="video/mp4">
                </video>
                <!-- <p style="font-size: 16px; text-align:center">Implicit BC policy on a precise, 1-millimeter-tolerance <br>slide-then-insert task: push a block across a table, then slide it into a slot.</p><br> -->

                <!-- <p>Below is a representative comparison on this insertion task:</p><br> -->
            </div>
            
            <!-- Highlight part -->
            <div class="section paper">
                <h1 style="margin-bottom: 0px">Real World Insert-T Task</h1>
                <p>The Insert-T task requires the robot to insert a T-shaped object into a U-shaped object by pushing. We categorize the task into three difficulty levels, and examples of the post-training policy rollouts for each level are shown below:</p><br>
                <h2 style="margin-bottom: 0px">Insert-T 'Easy' category:</h2> 
                <!-- <p style="font-size: 20px; margin-left: 0px"><b> Insert-T 'Easy' category: <b></p> -->
                <div class="section recent-work">
                    <div class="highlight-proj">
                        <video height="240" width="100%" playsinline="" muted="" autoplay="" loop="", style="margin-top: 0px;">
                            <source src="images/InsertT_easy_1.mp4" type="video/mp4">
                        </video>
                        <!-- <p style="font-size: 16px; margin-left: 0px">Precise cloning of <br> switching behaviors. <br> (shown: "2D Particle" task)</p> -->
                    </div>
                    <div class="highlight-proj">
                        <video height="240" width="100%" playsinline="" muted="" autoplay="" loop="", style="margin-top: 0px;">
                            <source src="images/InsertT_easy_2.mp4" type="video/mp4">
                        </video>
                        <!-- <p style="font-size: 16px; margin-left: 0px">State-of-the art results on D4RL human-expert tasks. <br> (shown: "door-human-v0" task)</p> -->
                    </div>
                    <div class="highlight-proj">
                        <video height="240" width="100%" playsinline="" muted="" autoplay="" loop="", style="margin-top: 0px;">
                            <source src="images/InsertT_easy_3.mp4" type="video/mp4">
                        </video>
                        <!-- <p style="font-size: 16px; margin-left: 0px">Works with high-dimensional observations and inputs. <br> (shown: "Bi-Manual Sweeping")</p> -->
                    </div>
                </div>
                <h2 style="margin-bottom: 0px">Insert-T 'Medium' category:</h2> 
                <!-- <p style="font-size: 20px; margin-left: 0px"><b> Insert-T 'Medium' category: <b></p> -->
                <div class="section recent-work">
                    <div class="highlight-proj">
                        <video height="240" width="100%" playsinline="" muted="" autoplay="" loop="", style="margin-top: 0px;">
                            <source src="images/InsertT_medium_1.mp4" type="video/mp4">
                        </video>
                        <!-- <p style="font-size: 16px; margin-left: 0px">Precise cloning of <br> switching behaviors. <br> (shown: "2D Particle" task)</p> -->
                    </div>
                    <div class="highlight-proj">
                        <video height="240" width="100%" playsinline="" muted="" autoplay="" loop="", style="margin-top: 0px;">
                            <source src="images/InsertT_medium_2.mp4" type="video/mp4">
                        </video>
                        <!-- <p style="font-size: 16px; margin-left: 0px">State-of-the art results on D4RL human-expert tasks. <br> (shown: "door-human-v0" task)</p> -->
                    </div>
                    <div class="highlight-proj">
                        <video height="240" width="100%" playsinline="" muted="" autoplay="" loop="", style="margin-top: 0px;">
                            <source src="images/InsertT_medium_3.mp4" type="video/mp4">
                        </video>
                        <!-- <p style="font-size: 16px; margin-left: 0px">Works with high-dimensional observations and inputs. <br> (shown: "Bi-Manual Sweeping")</p> -->
                    </div>
                </div>
                <h2 style="margin-bottom: 0px">Insert-T 'Hard' category:</h2> 
                <!-- <p style="font-size: 20px; margin-left: 0px"><b> Insert-T 'Medium' category: <b></p> -->
                <div class="section recent-work">
                    <div class="highlight-proj">
                        <video height="240" width="100%" playsinline="" muted="" autoplay="" loop="", style="margin-top: 0px;">
                            <source src="images/InsertT_hard_1.mp4" type="video/mp4">
                        </video>
                        <!-- <p style="font-size: 16px; margin-left: 0px">Precise cloning of <br> switching behaviors. <br> (shown: "2D Particle" task)</p> -->
                    </div>
                    <div class="highlight-proj">
                        <video height="240" width="100%" playsinline="" muted="" autoplay="" loop="", style="margin-top: 0px;">
                            <source src="images/InsertT_hard_2.mp4" type="video/mp4">
                        </video>
                        <!-- <p style="font-size: 16px; margin-left: 0px">State-of-the art results on D4RL human-expert tasks. <br> (shown: "door-human-v0" task)</p> -->
                    </div>
                    <div class="highlight-proj">
                        <video height="240" width="100%" playsinline="" muted="" autoplay="" loop="", style="margin-top: 0px;">
                            <source src="images/InsertT_hard_3.mp4" type="video/mp4">
                        </video>
                        <!-- <p style="font-size: 16px; margin-left: 0px">Works with high-dimensional observations and inputs. <br> (shown: "Bi-Manual Sweeping")</p> -->
                    </div>
                </div>
            </div>
                <div class="divider"></div>
                <br>

            



            <!-- <div class="section paper half">
                <h1>Code</h1>
                <p>
                    <a href="https://github.com/google-research/ibc">Code is available on Github!</a> Includes:<br>
                    <p style="font-size: 16px">
                    &nbsp;&nbsp;&bull;&nbsp;&nbsp;Simulation environments: Particle, Simulated Robot, D4RL tasks.<br>
                    &nbsp;&nbsp;&bull;&nbsp;&nbsp;Downloadable data for tasks.<br>
                    &nbsp;&nbsp;&bull;&nbsp;&nbsp;IBC implementation (Langevin and DFO).<br>
                    &nbsp;&nbsp;&bull;&nbsp;&nbsp;MSE and MDN baselines.<br>
                    &nbsp;&nbsp;&bull;&nbsp;&nbsp;Configurations for trainings.<br>
                    &nbsp;&nbsp;&bull;&nbsp;&nbsp;10-minute Quickstart.<br>
                   
                </p>
                </p> -->

            <!-- </div>
            <div class="section bibtex half">
                <h1>Bibtex</h1>
                <div class="code">@article{florence2021implicit,<br>
&nbsp;&nbsp;&nbsp;&nbsp;title={Implicit Behavioral Cloning},<br>
&nbsp;&nbsp;&nbsp;&nbsp;author={Florence, Pete and Lynch, Corey and Zeng, Andy and Ramirez, Oscar and Wahid, Ayzaan and Downs, Laura and Wong, Adrian and Lee, Johnny and Mordatch, Igor and Tompson, Jonathan},<br>
&nbsp;&nbsp;&nbsp;&nbsp;journal={Conference on Robot Learning (CoRL)},<br>
&nbsp;&nbsp;&nbsp;&nbsp;year={2021}<br>
}</div>
            </div>
            <br>
            <div class="divider"></div>
            <br>
             -->


            <div class="section team">
                <h1>Team</h1>
                <p>Omited for anonymous review.</p><br>
                <!-- <div class="people-profile">
                    <a href="http://www.peteflorence.com/"><img src="images/people/pete.jpg"><p>Pete Florence</p></a>
                </div>
                <div class="people-profile">
                    <a href="https://coreylynch.github.io/"><img src="images/people/corey.jpg"><p>Corey Lynch</p></a>
                </div>
                <div class="people-profile">
                    <a href="https://andyzeng.github.io/"><img src="images/people/andy.jpg"><p>Andy Zeng</p></a>
                </div>
                <div class="people-profile">
                    <a href="https://www.linkedin.com/in/oscar-ramirez-905913b9"><img src="images/people/oscar.jpg"><p>Oscar Ramirez</p></a>
                </div>
                <div class="people-profile">
                    <a href="https://ayzaan.com/"><img src="images/people/ayzaan.jpg"><p>Ayzaan Wahid</p></a>
                </div>
                <div class="people-profile">
                    <a href="https://www.linkedin.com/in/laura-downs-4935081"><img src="images/people/laura.jpg"><p>Laura Downs</p></a>
                </div>
                <div class="people-profile">
                    <a href="https://almostsquare.com/"><img src="images/people/adrian.png"><p>Adrian Wong</p></a>
                </div>
                <div class="people-profile">
                    <a href="http://johnnylee.net/"><img src="images/people/johnny.png"><p>Johnny Lee</p></a>
                </div>
                <div class="people-profile">
                    <a href="https://twitter.com/imordatch"><img src="images/people/igor.jpg"><p>Igor Mordatch</p></a>
                </div>
                <div class="people-profile">
                    <a href="https://jonathantompson.github.io/"><img src="images/people/jonathan_tompson.jpeg"><p>Jonathan Tompson</p></a>
                </div>
                 -->
                <div style="clear: both;"></div>
            </div>
            <!-- <div class="section teamlogo">
                <img src="images/logo.png">
                <p>Robotics at Google</p>
            </div> -->
            <div style="clear: both;"></div>
            <div class="divider"></div>
            
            
            
            
            <div class="divider"></div>
            
            <div class="section acknowledgements">
                <h1>Acknowledgements</h1>
                <p>Omited for anonymous review.</p><br><br>
            </div>
            <br><br><br><br><br><br><br><br><br><br>
            <div class="divider"></div>
        </div>
    </body>
</html>
